# ğŸ”„ æ¨¡å‹ä»£ç è½¬æ¢æŠ€æœ¯æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå¼ºå¤§çš„**å¯è§†åŒ–æ¨¡å‹åˆ°ä»£ç è½¬æ¢ç³»ç»Ÿ**ï¼Œèƒ½å¤Ÿå°†ç”¨æˆ·åœ¨å‰ç«¯æ‹–æ‹½æ„å»ºçš„ç¥ç»ç½‘ç»œæ¨¡å‹è‡ªåŠ¨è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„TensorFlowæˆ–PyTorchä»£ç ã€‚è¿™ä¸ªç³»ç»Ÿæ˜¯æ•´ä¸ªå¯è§†åŒ–æœºå™¨å­¦ä¹ å¹³å°çš„æ ¸å¿ƒç»„ä»¶ã€‚

## ğŸ—ï¸ æ•´ä½“æ¶æ„

### è½¬æ¢æµç¨‹æ¦‚è§ˆ
```
å¯è§†åŒ–æ¨¡å‹ç»“æ„ â†’ ç»“æ„åˆ†æ â†’ ä»£ç ç”Ÿæˆ â†’ å¯æ‰§è¡Œä»£ç 
     â†“              â†“          â†“          â†“
   JSONæ ¼å¼      ä¾èµ–åˆ†æ    æ¨¡æ¿å¡«å……    è®­ç»ƒæ‰§è¡Œ
```

### æ ¸å¿ƒç»„ä»¶
- **TensorFlowè½¬æ¢å™¨** (`tensorflow_converter.py`)
- **PyTorchè½¬æ¢å™¨** (`pytorch_converter.py`)
- **é€šç”¨åˆ†æå¼•æ“** (ç»“æ„è§£æã€ä¾èµ–åˆ†æ)
- **ä»£ç ç”Ÿæˆå¼•æ“** (æ¨¡æ¿ç³»ç»Ÿã€åŠ¨æ€ç”Ÿæˆ)

## ğŸ” è½¬æ¢æœºåˆ¶è¯¦è§£

### 1. è¾“å…¥æ•°æ®ç»“æ„

#### å±‚é…ç½®æ ¼å¼
```json
{
  "id": "layer_001",
  "type": "conv2d",
  "position": {"x": 100, "y": 200},
  "config": {
    "filters": 32,
    "kernelSize": [3, 3],
    "strides": [1, 1],
    "activation": "relu",
    "padding": "same"
  }
}
```

#### è¿æ¥å…³ç³»æ ¼å¼
```json
{
  "source": "layer_001",
  "target": "layer_002",
  "sourceHandle": "output",
  "targetHandle": "input"
}
```

### 2. ç»“æ„åˆ†æé˜¶æ®µ

#### ğŸ”— ä¾èµ–å…³ç³»æ„å»º
```python
def _analyze_model_structure(self, layers, connections):
    # 1. æ„å»ºè¿æ¥å›¾
    connection_map = {}
    for conn in connections:
        source = conn.get('source')
        target = conn.get('target')
        if target not in connection_map:
            connection_map[target] = []
        connection_map[target].append(source)
    
    # 2. åˆ†ç±»å±‚ç±»å‹
    input_layers = [layer for layer in layers 
                   if layer['type'] in ['useData', 'mnist']]
    processing_layers = [layer for layer in layers 
                        if layer['type'] not in ['useData', 'mnist']]
    
    # 3. æ‹“æ‰‘æ’åº
    sorted_layers = self._topological_sort(processing_layers, connection_map)
    
    return {
        'input_layers': input_layers,
        'processing_layers': sorted_layers,
        'connections': connection_map,
        'has_mnist': any(layer['type'] == 'mnist' for layer in input_layers),
        'has_csv': any(layer['type'] == 'useData' for layer in input_layers)
    }
```

#### ğŸ”„ æ‹“æ‰‘æ’åºç®—æ³•
```python
def _topological_sort(self, layers, connections):
    """
    ç¡®ä¿å±‚çš„æ‰§è¡Œé¡ºåºç¬¦åˆä¾èµ–å…³ç³»
    ä½¿ç”¨Kahnç®—æ³•çš„ç®€åŒ–ç‰ˆæœ¬
    """
    sorted_layers = []
    remaining_layers = layers.copy()
    
    while remaining_layers:
        # æ‰¾åˆ°æ²¡æœ‰æœªæ»¡è¶³ä¾èµ–çš„å±‚
        ready_layers = []
        for layer in remaining_layers:
            dependencies = connections.get(layer['id'], [])
            all_deps_ready = all(
                not any(l['id'] == dep for l in remaining_layers)
                for dep in dependencies
            )
            if all_deps_ready:
                ready_layers.append(layer)
        
        if not ready_layers:
            # æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–
            logger.warning("æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–ï¼Œä½¿ç”¨åŸå§‹é¡ºåº")
            sorted_layers.extend(remaining_layers)
            break
        
        # ç§»é™¤å·²å¤„ç†çš„å±‚
        for layer in ready_layers:
            sorted_layers.append(layer)
            remaining_layers.remove(layer)
    
    return sorted_layers
```

### 3. ä»£ç ç”Ÿæˆé˜¶æ®µ

## ğŸ”§ TensorFlowè½¬æ¢å™¨

### æ¶æ„ç‰¹ç‚¹
- **Sequentialæ¨¡å‹** - ä½¿ç”¨Keras Sequential API
- **å‡½æ•°å¼ç¼–ç¨‹** - ç”Ÿæˆç‹¬ç«‹çš„å‡½æ•°æ¨¡å—
- **è‡ªåŠ¨æ•°æ®å¤„ç†** - å†…ç½®æ•°æ®åŠ è½½å’Œé¢„å¤„ç†

### æ ¸å¿ƒè½¬æ¢é€»è¾‘

#### ğŸ—ï¸ æ¨¡å‹å®šä¹‰ç”Ÿæˆ
```python
def _generate_model_definition(self, model_info):
    """ç”ŸæˆTensorFlowæ¨¡å‹å®šä¹‰"""
    code = ["def create_model():"]
    code.append("    logger.info('åˆ›å»ºTensorFlowæ¨¡å‹...')")
    code.append("    model = keras.Sequential([")
    
    # éå†æ¯ä¸€å±‚
    for i, layer in enumerate(model_info['processing_layers']):
        is_first = (i == 0)
        layer_code = self._generate_layer_code(layer, is_first, model_info)
        code.append(f"        {layer_code},")
    
    code.append("    ])")
    code.append("    return model")
    return "\n".join(code)
```

#### ğŸ§© å±‚è½¬æ¢ç¤ºä¾‹

**å·ç§¯å±‚è½¬æ¢**
```python
def _create_conv2d(self, config, is_first, model_info):
    filters = config.get('filters', 32)
    kernel_size = config.get('kernelSize', [3, 3])
    strides = config.get('strides', [1, 1])
    activation = config.get('activation', 'relu')
    padding = config.get('padding', 'same')
    
    # ç¬¬ä¸€å±‚éœ€è¦æŒ‡å®šè¾“å…¥å½¢çŠ¶
    if is_first:
        if model_info['has_mnist']:
            input_shape = "(28, 28, 1)"
        else:
            input_shape = "(None,)"  # åŠ¨æ€å½¢çŠ¶
        
        return f"layers.Conv2D({filters}, {kernel_size}, " \
               f"strides={strides}, activation='{activation}', " \
               f"padding='{padding}', input_shape={input_shape})"
    else:
        return f"layers.Conv2D({filters}, {kernel_size}, " \
               f"strides={strides}, activation='{activation}', " \
               f"padding='{padding}')"
```

**å…¨è¿æ¥å±‚è½¬æ¢**
```python
def _create_dense(self, config, is_first, model_info):
    units = config.get('units', 128)
    activation = config.get('activation', 'relu')
    
    if is_first and model_info['has_csv']:
        # CSVæ•°æ®çš„ç¬¬ä¸€å±‚éœ€è¦æŒ‡å®šè¾“å…¥ç»´åº¦
        return f"layers.Dense({units}, activation='{activation}', " \
               f"input_shape=(None,))"
    else:
        return f"layers.Dense({units}, activation='{activation}')"
```

#### ğŸ“Š æ•°æ®åŠ è½½ç”Ÿæˆ

**MNISTæ•°æ®åŠ è½½å™¨**
```python
def _generate_mnist_loader(self):
    return '''
def load_mnist_data():
    """åŠ è½½å¹¶é¢„å¤„ç†MNISTæ•°æ®é›†"""
    logger.info("åŠ è½½MNISTæ•°æ®é›†...")
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
    
    # æ•°æ®å½’ä¸€åŒ–
    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0
    
    # æ·»åŠ é€šé“ç»´åº¦ (28, 28) -> (28, 28, 1)
    x_train = np.expand_dims(x_train, -1)
    x_test = np.expand_dims(x_test, -1)
    
    # One-hotç¼–ç 
    y_train = keras.utils.to_categorical(y_train, 10)
    y_test = keras.utils.to_categorical(y_test, 10)
    
    return (x_train, y_train), (x_test, y_test)
'''
```

#### ğŸ¯ è®­ç»ƒå‡½æ•°ç”Ÿæˆ
```python
def _generate_training_function(self):
    return '''
def train_model(model, train_data, test_data, epochs=10, batch_size=32):
    """è®­ç»ƒæ¨¡å‹"""
    x_train, y_train = train_data
    x_test, y_test = test_data
    
    # ç¼–è¯‘æ¨¡å‹
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # è®­ç»ƒå›è°ƒ
    callbacks = [
        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),
        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)
    ]
    
    # å¼€å§‹è®­ç»ƒ
    history = model.fit(
        x_train, y_train,
        batch_size=batch_size,
        epochs=epochs,
        validation_data=(x_test, y_test),
        callbacks=callbacks,
        verbose=1
    )
    
    return history
'''
```

## âš¡ PyTorchè½¬æ¢å™¨

### æ¶æ„ç‰¹ç‚¹
- **ç±»å®šä¹‰æ¨¡å¼** - ç”Ÿæˆç»§æ‰¿nn.Moduleçš„æ¨¡å‹ç±»
- **æ˜¾å¼å‰å‘ä¼ æ’­** - æ‰‹åŠ¨å®šä¹‰forwardæ–¹æ³•
- **çµæ´»çš„æ•°æ®å¤„ç†** - DataLoaderé›†æˆ

### æ ¸å¿ƒè½¬æ¢é€»è¾‘

#### ğŸ—ï¸ æ¨¡å‹ç±»ç”Ÿæˆ
```python
def _generate_model_class(self, model_info):
    """ç”ŸæˆPyTorchæ¨¡å‹ç±»"""
    code = ["class VisualModel(nn.Module):"]
    code.append("    def __init__(self):")
    code.append("        super(VisualModel, self).__init__()")
    code.append("        logger.info('åˆå§‹åŒ–PyTorchæ¨¡å‹...')")
    
    # æ·»åŠ å±‚å®šä¹‰
    for i, layer in enumerate(model_info['processing_layers']):
        layer_def = self._generate_layer_definition(layer, i, model_info)
        code.append(f"        {layer_def}")
    
    # å‰å‘ä¼ æ’­æ–¹æ³•
    code.append("")
    code.append("    def forward(self, x):")
    for i, layer in enumerate(model_info['processing_layers']):
        forward_code = self._generate_forward_code(layer, i)
        code.append(f"        {forward_code}")
    
    code.append("        return x")
    return "\n".join(code)
```

#### ğŸ§© å±‚å®šä¹‰ç¤ºä¾‹

**å·ç§¯å±‚å®šä¹‰**
```python
def _create_conv2d(self, config, index, model_info):
    filters = config.get('filters', 32)
    kernel_size = config.get('kernelSize', 3)
    stride = config.get('strides', 1)
    
    # è®¡ç®—è¾“å…¥é€šé“æ•°
    if index == 0 and model_info['has_mnist']:
        in_channels = 1  # MNISTç°åº¦å›¾
    else:
        in_channels = self._calculate_in_channels(index, model_info)
    
    return f"self.conv2d_{index} = nn.Conv2d({in_channels}, {filters}, " \
           f"{kernel_size}, stride={stride})"
```

**å‰å‘ä¼ æ’­ä»£ç **
```python
def _generate_forward_code(self, layer, index):
    layer_type = layer['type']
    
    if layer_type == 'conv2d':
        return f"x = self.conv2d_{index}(x)"
    elif layer_type == 'flatten':
        return f"x = x.view(x.size(0), -1)"  # å±•å¹³æ“ä½œ
    elif layer_type == 'activation':
        activation = layer.get('config', {}).get('activation', 'relu')
        return f"x = F.{activation}(x)"
    else:
        return f"x = self.{layer_type}_{index}(x)"
```

#### ğŸ¯ è®­ç»ƒå¾ªç¯ç”Ÿæˆ
```python
def _generate_training_function(self):
    return '''
def train_model(model, train_loader, test_loader, epochs=10, lr=0.001):
    """è®­ç»ƒPyTorchæ¨¡å‹"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        test_loss = 0.0
        test_correct = 0
        test_total = 0
        
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                loss = criterion(output, target)
                
                test_loss += loss.item()
                _, predicted = output.max(1)
                test_total += target.size(0)
                test_correct += predicted.eq(target).sum().item()
        
        scheduler.step()
        
        logger.info(f'Epoch {epoch+1}/{epochs}: '
                   f'Train Loss: {train_loss/len(train_loader):.4f}, '
                   f'Train Acc: {100.*correct/total:.2f}%, '
                   f'Test Loss: {test_loss/len(test_loader):.4f}, '
                   f'Test Acc: {100.*test_correct/test_total:.2f}%')
    
    return model
'''
```

## ğŸ”§ é«˜çº§ç‰¹æ€§

### 1. æ™ºèƒ½å½¢çŠ¶æ¨æ–­

#### é—®é¢˜æè¿°
åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå±‚ä¹‹é—´çš„æ•°æ®å½¢çŠ¶åŒ¹é…æ˜¯å…³é”®é—®é¢˜ã€‚æˆ‘ä»¬çš„è½¬æ¢å™¨å®ç°äº†æ™ºèƒ½å½¢çŠ¶æ¨æ–­ï¼š

```python
def _calculate_output_shape(self, layer, input_shape):
    """è®¡ç®—å±‚çš„è¾“å‡ºå½¢çŠ¶"""
    layer_type = layer['type']
    config = layer.get('config', {})
    
    if layer_type == 'conv2d':
        filters = config.get('filters', 32)
        kernel_size = config.get('kernelSize', [3, 3])
        strides = config.get('strides', [1, 1])
        padding = config.get('padding', 'same')
        
        if padding == 'same':
            output_h = input_shape[1] // strides[0]
            output_w = input_shape[2] // strides[1]
        else:  # 'valid'
            output_h = (input_shape[1] - kernel_size[0]) // strides[0] + 1
            output_w = (input_shape[2] - kernel_size[1]) // strides[1] + 1
        
        return (input_shape[0], output_h, output_w, filters)
    
    elif layer_type == 'flatten':
        return (input_shape[0], np.prod(input_shape[1:]))
    
    # ... å…¶ä»–å±‚ç±»å‹çš„å½¢çŠ¶è®¡ç®—
```

### 2. é”™è¯¯æ£€æµ‹ä¸ä¿®å¤

#### å¸¸è§é”™è¯¯å¤„ç†
```python
def _validate_model_structure(self, model_info):
    """éªŒè¯æ¨¡å‹ç»“æ„çš„åˆç†æ€§"""
    errors = []
    warnings = []
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥å±‚
    if not model_info['input_layers']:
        errors.append("æ¨¡å‹å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªè¾“å…¥å±‚")
    
    # æ£€æŸ¥å±‚çš„è¿æ¥æ€§
    for layer in model_info['processing_layers']:
        layer_id = layer['id']
        if layer_id not in model_info['connections'] and layer != model_info['processing_layers'][0]:
            warnings.append(f"å±‚ {layer_id} å¯èƒ½æ²¡æœ‰è¾“å…¥è¿æ¥")
    
    # æ£€æŸ¥æ¿€æ´»å‡½æ•°çš„åˆç†æ€§
    for layer in model_info['processing_layers']:
        if layer['type'] == 'dense':
            activation = layer.get('config', {}).get('activation')
            if layer == model_info['processing_layers'][-1] and activation != 'softmax':
                warnings.append("æœ€åä¸€å±‚å»ºè®®ä½¿ç”¨softmaxæ¿€æ´»å‡½æ•°")
    
    return errors, warnings
```

### 3. ä¼˜åŒ–ç­–ç•¥

#### ä»£ç ä¼˜åŒ–
```python
def _optimize_model_structure(self, model_info):
    """ä¼˜åŒ–æ¨¡å‹ç»“æ„"""
    optimized_layers = []
    
    for i, layer in enumerate(model_info['processing_layers']):
        # åˆå¹¶è¿ç»­çš„æ¿€æ´»å±‚
        if (layer['type'] == 'activation' and 
            i > 0 and 
            optimized_layers[-1]['type'] in ['conv2d', 'dense']):
            
            # å°†æ¿€æ´»å‡½æ•°åˆå¹¶åˆ°å‰ä¸€å±‚
            prev_layer = optimized_layers[-1]
            prev_layer['config']['activation'] = layer['config']['activation']
            continue
        
        # ç§»é™¤å†—ä½™çš„dropoutå±‚
        if (layer['type'] == 'dropout' and 
            layer['config'].get('rate', 0) == 0):
            continue
        
        optimized_layers.append(layer)
    
    model_info['processing_layers'] = optimized_layers
    return model_info
```

## ğŸ“Š æ”¯æŒçš„å±‚ç±»å‹

### åŸºç¡€å±‚
| å±‚ç±»å‹ | TensorFlow | PyTorch | é…ç½®å‚æ•° |
|--------|------------|---------|----------|
| Dense | âœ… | âœ… | units, activation |
| Conv2D | âœ… | âœ… | filters, kernel_size, strides |
| MaxPooling2D | âœ… | âœ… | pool_size, strides |
| AvgPooling2D | âœ… | âœ… | pool_size, strides |
| Dropout | âœ… | âœ… | rate |
| BatchNorm | âœ… | âœ… | - |
| Flatten | âœ… | âœ… | - |

### é«˜çº§å±‚
| å±‚ç±»å‹ | TensorFlow | PyTorch | é…ç½®å‚æ•° |
|--------|------------|---------|----------|
| LSTM | âœ… | âœ… | units, return_sequences |
| GRU | âœ… | âœ… | units, return_sequences |
| Activation | âœ… | âœ… | activation |
| Reshape | âœ… | âœ… | target_shape |

### è¾“å…¥å±‚
| å±‚ç±»å‹ | æè¿° | æ”¯æŒæ ¼å¼ |
|--------|------|----------|
| MNIST | å†…ç½®MNISTæ•°æ®é›† | 28x28ç°åº¦å›¾ |
| UseData | è‡ªå®šä¹‰æ•°æ® | CSV, Excel, JSON |

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### å‰ç«¯æ¨¡å‹å®šä¹‰
```javascript
const modelStructure = {
  layers: [
    {
      id: "input_1",
      type: "mnist",
      config: {}
    },
    {
      id: "conv_1",
      type: "conv2d",
      config: {
        filters: 32,
        kernelSize: [3, 3],
        activation: "relu"
      }
    },
    {
      id: "pool_1",
      type: "maxPooling2d",
      config: {
        poolSize: [2, 2]
      }
    },
    {
      id: "flatten_1",
      type: "flatten",
      config: {}
    },
    {
      id: "dense_1",
      type: "dense",
      config: {
        units: 10,
        activation: "softmax"
      }
    }
  ],
  connections: [
    {source: "input_1", target: "conv_1"},
    {source: "conv_1", target: "pool_1"},
    {source: "pool_1", target: "flatten_1"},
    {source: "flatten_1", target: "dense_1"}
  ]
};
```

### ç”Ÿæˆçš„TensorFlowä»£ç 
```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

def create_model():
    model = keras.Sequential([
        layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28, 28, 1)),
        layers.MaxPooling2D([2, 2]),
        layers.Flatten(),
        layers.Dense(10, activation='softmax')
    ])
    return model

def load_mnist_data():
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0
    x_train = np.expand_dims(x_train, -1)
    x_test = np.expand_dims(x_test, -1)
    y_train = keras.utils.to_categorical(y_train, 10)
    y_test = keras.utils.to_categorical(y_test, 10)
    return (x_train, y_train), (x_test, y_test)

def main():
    model = create_model()
    (x_train, y_train), (x_test, y_test) = load_mnist_data()
    train_model(model, (x_train, y_train), (x_test, y_test))
```

### ç”Ÿæˆçš„PyTorchä»£ç 
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class VisualModel(nn.Module):
    def __init__(self):
        super(VisualModel, self).__init__()
        self.conv2d_0 = nn.Conv2d(1, 32, 3)
        self.maxpool_1 = nn.MaxPool2d(2)
        self.dense_3 = nn.Linear(5408, 10)  # è®¡ç®—å¾—å‡ºçš„ç‰¹å¾æ•°
    
    def forward(self, x):
        x = F.relu(self.conv2d_0(x))
        x = self.maxpool_1(x)
        x = x.view(x.size(0), -1)
        x = F.softmax(self.dense_3(x), dim=1)
        return x

def main():
    model = VisualModel()
    train_loader, test_loader = load_mnist_data()
    train_model(model, train_loader, test_loader)
```

## ğŸ”® æœªæ¥æ‰©å±•

### è®¡åˆ’ä¸­çš„åŠŸèƒ½
1. **æ›´å¤šå±‚ç±»å‹æ”¯æŒ**
   - Transformerå±‚
   - æ³¨æ„åŠ›æœºåˆ¶
   - æ®‹å·®è¿æ¥

2. **é«˜çº§ä¼˜åŒ–**
   - è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜
   - æ¨¡å‹å‹ç¼©
   - é‡åŒ–æ”¯æŒ

3. **éƒ¨ç½²æ”¯æŒ**
   - ONNXå¯¼å‡º
   - TensorRTä¼˜åŒ–
   - ç§»åŠ¨ç«¯éƒ¨ç½²

4. **å¯è§†åŒ–å¢å¼º**
   - å®æ—¶è®­ç»ƒå¯è§†åŒ–
   - æ¨¡å‹ç»“æ„å›¾
   - æ€§èƒ½åˆ†æ

## ğŸ“š æŠ€æœ¯ç»†èŠ‚

### è®¾è®¡æ¨¡å¼
- **ç­–ç•¥æ¨¡å¼** - ä¸åŒæ¡†æ¶çš„è½¬æ¢å™¨
- **æ¨¡æ¿æ–¹æ³•æ¨¡å¼** - ä»£ç ç”Ÿæˆæµç¨‹
- **å·¥å‚æ¨¡å¼** - å±‚å¯¹è±¡åˆ›å»º

### æ€§èƒ½ä¼˜åŒ–
- **å»¶è¿ŸåŠ è½½** - æŒ‰éœ€ç”Ÿæˆä»£ç 
- **ç¼“å­˜æœºåˆ¶** - é‡å¤ç»“æ„ç¼“å­˜
- **å¹¶è¡Œå¤„ç†** - å¤šå±‚å¹¶è¡Œåˆ†æ

### é”™è¯¯å¤„ç†
- **ç»“æ„éªŒè¯** - æ¨¡å‹åˆç†æ€§æ£€æŸ¥
- **ç±»å‹æ£€æŸ¥** - å‚æ•°ç±»å‹éªŒè¯
- **å¼‚å¸¸æ¢å¤** - è‡ªåŠ¨é”™è¯¯ä¿®å¤

è¿™ä¸ªè½¬æ¢ç³»ç»Ÿæ˜¯æ•´ä¸ªå¯è§†åŒ–æœºå™¨å­¦ä¹ å¹³å°çš„æ ¸å¿ƒï¼Œå®ƒå°†ç”¨æˆ·çš„ç›´è§‚æ“ä½œè½¬åŒ–ä¸ºä¸“ä¸šçš„æ·±åº¦å­¦ä¹ ä»£ç ï¼Œå¤§å¤§é™ä½äº†æœºå™¨å­¦ä¹ çš„å…¥é—¨é—¨æ§›ã€‚ 