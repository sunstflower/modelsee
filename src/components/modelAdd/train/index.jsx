import React, { useCallback } from 'react';
import * as tf from '@tensorflow/tfjs';
import * as tfvis from '@tensorflow/tfjs-vis';
import { MnistData } from '@/tfjs/data.js'; // ç¡®ä¿è·¯å¾„æ­£ç¡®
import useStore from '@/store'; // ç¡®ä¿è·¯å¾„æ­£ç¡®
import mlBackendService from '../../../services/mlBackendService';
import { useEffect } from 'react';

async function showExamples(data) {
  const surface = tfvis.visor().surface({ name: 'Input Data Examples', tab: 'Input Data' });
  const examples = data.nextTestBatch(20);
  const numExamples = examples.xs.shape[0];

  for (let i = 0; i < numExamples; i++) {
    const imageTensor = tf.tidy(() => {
      return examples.xs.slice([i, 0], [1, examples.xs.shape[1]]).reshape([28, 28, 1]);
    });

    const canvas = document.createElement('canvas');
    canvas.width = 28;
    canvas.height = 28;
    canvas.style = 'margin: 4px;';
    await tf.browser.toPixels(imageTensor, canvas);
    surface.drawArea.appendChild(canvas);

    imageTensor.dispose();
  }
}

function getModel(conv2dConfigs, maxPooling2dConfigs, denseConfigs, nodes, edges) {
  const model = tf.sequential();
  const IMAGE_WIDTH = 28;
  const IMAGE_HEIGHT = 28;
  const IMAGE_CHANNELS = 1;

  // æ£€æŸ¥è¾“å…¥å‚æ•°
  if (!nodes || nodes.length === 0) {
    console.error('No nodes found in the model structure');
    return model;
  }

  if (!edges || edges.length === 0) {
    console.error('No edges found in the model structure');
    return model;
  }

  console.log('Building model with nodes:', nodes);
  console.log('Building model with edges:', edges);

  // æ„å»ºé‚»æ¥è¡¨
  const adjacencyList = {};
  nodes.forEach(node => {
    adjacencyList[node.id] = {
      node,
      next: [],
    };
  });

  // å¡«å……é‚»æ¥è¡¨çš„nextæ•°ç»„
  edges.forEach(edge => {
    if (adjacencyList[edge.source]) {
      adjacencyList[edge.source].next.push(edge.target);
    }
  });

  // æ‰¾åˆ°æ²¡æœ‰å…¥è¾¹çš„èŠ‚ç‚¹(æºèŠ‚ç‚¹)
  const inDegree = {};
  nodes.forEach(node => {
    inDegree[node.id] = 0;
  });

  edges.forEach(edge => {
    inDegree[edge.target]++;
  });

  const sources = nodes
    .filter(node => inDegree[node.id] === 0)
    .map(node => node.id);

  console.log('Found sources:', sources);

  // å¦‚æœæ²¡æœ‰æºèŠ‚ç‚¹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä½œä¸ºèµ·ç‚¹
  const startNode = sources.length > 0 ? sources[0] : nodes[0].id;
  console.log('Starting from node:', startNode);

  // ä½¿ç”¨BFSéå†å›¾è·å–æœ‰åºæ¨¡å‹ç»“æ„
  const visited = new Set();
  const queue = [startNode];
  let hasAddedFlatten = false;
  let layerCount = 0;

  while (queue.length > 0) {
    const currentId = queue.shift();

    if (visited.has(currentId)) continue;
    visited.add(currentId);

    const current = adjacencyList[currentId];
    if (!current) {
      console.warn(`Node ${currentId} not found in adjacency list`);
      continue;
    }

    const { node } = current;
    console.log(`Processing node:`, node);

    // åªæ·»åŠ å®é™…çš„å±‚èŠ‚ç‚¹ï¼Œè·³è¿‡æ•°æ®æºèŠ‚ç‚¹
    if (node.type !== 'mnist' && node.type !== 'useData') {
      switch (node.type) {
        case 'conv2d':
          if (layerCount === 0) {
            // ç¬¬ä¸€ä¸ªConv2Då±‚éœ€è¦æŒ‡å®šinputShape
            console.log('Adding first Conv2D layer with inputShape');
            model.add(tf.layers.conv2d({
              inputShape: [IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS],
              ...conv2dConfigs[node.configIndex]
            }));
          } else {
            console.log('Adding Conv2D layer');
            model.add(tf.layers.conv2d(conv2dConfigs[node.configIndex]));
          }
          layerCount++;
          break;
        case 'maxPooling2d':
          console.log('Adding MaxPooling2D layer');
          model.add(tf.layers.maxPooling2d(maxPooling2dConfigs[node.configIndex]));
          layerCount++;
          break;
        case 'dense':
          // åœ¨æ·»åŠ Denseå±‚ä¹‹å‰ï¼Œæ£€æŸ¥ä¸Šä¸€å±‚çš„ç±»å‹
          // å¦‚æœå‰ä¸€å±‚æ˜¯GRUæˆ–LSTMï¼Œå®ƒä»¬å·²ç»è¾“å‡º2Då¼ é‡ï¼Œä¸éœ€è¦æ·»åŠ Flatten
          const prevLayerType = model.layers.length > 0 ? model.layers[model.layers.length - 1].constructor.name.toLowerCase() : '';
          const needFlatten = !hasAddedFlatten && 
                              !prevLayerType.includes('gru') && 
                              !prevLayerType.includes('lstm') &&
                              !prevLayerType.includes('dense') && 
                              !prevLayerType.includes('dropout') &&
                              !prevLayerType.includes('activation');
          
          if (needFlatten) {
            console.log('Adding Flatten layer before Dense layer');
            model.add(tf.layers.flatten());
            hasAddedFlatten = true;
            layerCount++;
          } else if (prevLayerType) {
            console.log(`Connecting Dense directly to ${prevLayerType} (Flatten not needed)`);
          }
          
          console.log('Adding Dense layer');
          model.add(tf.layers.dense(denseConfigs[node.configIndex] || denseConfigs[0]));
          layerCount++;
          break;
        case 'dropout':
          console.log('Adding Dropout layer');
          model.add(tf.layers.dropout(useStore.getState().dropoutConfigs[node.configIndex]));
          layerCount++;
          break;
        case 'batchNorm':
          console.log('Adding BatchNormalization layer');
          model.add(tf.layers.batchNormalization(useStore.getState().batchNormConfigs[node.configIndex]));
          layerCount++;
          break;
        case 'flatten':
          console.log('Adding Flatten layer');
          model.add(tf.layers.flatten());
          hasAddedFlatten = true;
          layerCount++;
          break;
        case 'lstm':
          if (layerCount === 0) {
            // ç¬¬ä¸€ä¸ªLSTMå±‚éœ€è¦æŒ‡å®šinputShape
            console.log('Adding first LSTM layer with inputShape');
            model.add(tf.layers.lstm({
              inputShape: [null, 28], // å‡è®¾è¾“å…¥æ˜¯åºåˆ—æ•°æ®ï¼Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
              ...useStore.getState().lstmConfigs[node.configIndex]
            }));
          } else {
            console.log('Adding LSTM layer');
            model.add(tf.layers.lstm(useStore.getState().lstmConfigs[node.configIndex]));
          }
          layerCount++;
          break;
        case 'gru':
          if (layerCount === 0) {
            // ç¬¬ä¸€ä¸ªGRUå±‚éœ€è¦æŒ‡å®šinputShapeï¼Œæ ¹æ®æ•°æ®æºåŠ¨æ€è°ƒæ•´
            console.log('Adding first GRU layer with inputShape');
            
            // è·å–CSVæ•°æ®ä¿¡æ¯ï¼Œå¦‚æœæœ‰çš„è¯
            const csvData = useStore.getState().csvData;
            let featuresDim = 28; // é»˜è®¤å€¼ï¼Œé€‚ç”¨äºMNISTæ•°æ®
            
            // å¦‚æœCSVæ•°æ®å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹ç‰¹å¾ç»´åº¦
            if (csvData && csvData.length > 0) {
              const numericColumns = [];
              // è¯†åˆ«æ‰€æœ‰æ•°å€¼åˆ—
              if (csvData[0]) {
                Object.keys(csvData[0]).forEach(key => {
                  if (key !== 'label' && key !== 'date' && 
                      (typeof csvData[0][key] === 'number' || !isNaN(parseFloat(csvData[0][key])))) {
                    numericColumns.push(key);
                  }
                });
              }
              
              if (numericColumns.length > 0) {
                featuresDim = numericColumns.length;
              }
            }
            
            console.log(`Detected features dimension for GRU: ${featuresDim}`);
            
            model.add(tf.layers.gru({
              inputShape: [null, featuresDim], // åŠ¨æ€è®¾ç½®ç‰¹å¾ç»´åº¦
              ...useStore.getState().gruConfigs[node.configIndex]
            }));
          } else {
            console.log('Adding GRU layer');
            model.add(tf.layers.gru(useStore.getState().gruConfigs[node.configIndex]));
          }
          layerCount++;
          break;
        case 'activation':
          console.log('Adding Activation layer');
          model.add(tf.layers.activation(useStore.getState().activationConfigs[node.configIndex]));
          layerCount++;
          break;
        case 'reshape':
          console.log('Adding Reshape layer');
          model.add(tf.layers.reshape(useStore.getState().reshapeConfigs[node.configIndex]));
          layerCount++;
          break;
        case 'avgPooling2d':
          console.log('Adding AvgPooling2D layer');
          model.add(tf.layers.averagePooling2d(useStore.getState().avgPooling2dConfigs[node.configIndex]));
          layerCount++;
          break;
        default:
          console.warn(`Unknown node type: ${node.type}`);
      }
    }

    // å°†æ‰€æœ‰æœªè®¿é—®çš„é‚»å±…åŠ å…¥é˜Ÿåˆ—
    current.next.forEach(nextId => {
      if (!visited.has(nextId)) {
        queue.push(nextId);
      }
    });
  }

  console.log(`Total layers added: ${layerCount}`);

  if (layerCount === 0) {
    console.error('No layers were added to the model');
    return model;
  }

  // ç¼–è¯‘æ¨¡å‹
  const optimizer = tf.train.adam();
  model.compile({
    optimizer: optimizer,
    loss: 'categoricalCrossentropy',
    metrics: ['accuracy'],
  });

  return model;
}

async function train(model, data, isCsv) {
  const metrics = ['loss', 'val_loss', 'acc', 'val_acc'];
  const container = { name: 'Model Training', tab: 'Model', styles: { height: '1000px' } };
  const fitCallbacks = tfvis.show.fitCallbacks(container, metrics);

  let trainXs, trainYs, testXs, testYs;

  if (isCsv) {
    // å¤„ç†CSVæ•°æ®ï¼Œæ£€æµ‹æ•°å€¼åˆ—
    console.log('Processing CSV data for training');
    const numericColumns = [];
    
    // è¯†åˆ«æ‰€æœ‰æ•°å€¼åˆ—
    if (data.length > 0 && data[0]) {
      Object.keys(data[0]).forEach(key => {
        if (key !== 'label' && key !== 'date' && 
            (typeof data[0][key] === 'number' || !isNaN(parseFloat(data[0][key])))) {
          numericColumns.push(key);
        }
      });
    }
    
    console.log('Detected numeric columns:', numericColumns);
    
    if (numericColumns.length === 0) {
      console.error('No numeric columns found in CSV data');
      return;
    }
    
    // æå–ç‰¹å¾å’Œæ ‡ç­¾
    const features = data.map(row => {
      return numericColumns.map(col => {
        const value = typeof row[col] === 'number' ? row[col] : parseFloat(row[col]);
        return isNaN(value) ? 0 : value;
      });
    });
    
    console.log(`Extracted ${features.length} samples, each with ${features[0].length} features`);
    
    // æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿè¿›è¡Œè®­ç»ƒ
    if (features.length < 10) {
      console.error('Not enough data samples for training (minimum 10 required)');
      return;
    }
    
    const labelField = 'label';
    const labels = data.map(row => Number(row[labelField] || 0));
    const uniqueLabels = [...new Set(labels)];
    const numClasses = Math.max(uniqueLabels.length, 3); // è‡³å°‘æœ‰3ä¸ªç±»åˆ«
    
    // æ•°æ®æ ‡å‡†åŒ– - å¯¹æ¯ä¸ªç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
    const featureMeans = [];
    const featureStds = [];
    
    // è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å‡å€¼
    for (let i = 0; i < features[0].length; i++) {
      let sum = 0;
      for (let j = 0; j < features.length; j++) {
        sum += features[j][i];
      }
      featureMeans.push(sum / features.length);
    }
    
    // è®¡ç®—æ¯ä¸ªç‰¹å¾çš„æ ‡å‡†å·®
    for (let i = 0; i < features[0].length; i++) {
      let sumSquaredDiff = 0;
      for (let j = 0; j < features.length; j++) {
        sumSquaredDiff += Math.pow(features[j][i] - featureMeans[i], 2);
      }
      featureStds.push(Math.sqrt(sumSquaredDiff / features.length) || 1);
    }
    
    // æ ‡å‡†åŒ–ç‰¹å¾
    const normalizedFeatures = features.map(sample => {
      return sample.map((value, index) => {
        return (value - featureMeans[index]) / featureStds[index];
      });
    });
    
    console.log('Feature statistics:');
    console.log('- Means:', featureMeans);
    console.log('- Standard deviations:', featureStds);
    
    console.log(`Found ${numClasses} unique classes in label column`);
    
    // åˆ›å»ºæ­£ç¡®çš„3Dæ•°ç»„ç»“æ„ [samples, timesteps, features]
    const reshapedFeatures = [];
    for (let i = 0; i < normalizedFeatures.length; i++) {
      const sample = [];
      sample.push(normalizedFeatures[i]); // ä¸€ä¸ªæ ·æœ¬åªæœ‰ä¸€ä¸ªæ—¶é—´æ­¥
      reshapedFeatures.push(sample);
    }
    
    console.log('Final tensor shape:', 
      `[${reshapedFeatures.length}, ${reshapedFeatures[0].length}, ${reshapedFeatures[0][0].length}]`);
    
    // åˆ›å»ºå¼ é‡
    const xs = tf.tensor3d(reshapedFeatures);
    const ys = tf.oneHot(labels, numClasses);
    
    console.log('Created tensors -', 
      'Features:', xs.shape, 
      'Labels:', ys.shape);
    
    // åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    const splitIndex = Math.floor(xs.shape[0] * 0.8);
    [trainXs, testXs] = tf.split(xs, [splitIndex, xs.shape[0] - splitIndex]);
    [trainYs, testYs] = tf.split(ys, [splitIndex, ys.shape[0] - splitIndex]);
    
    xs.dispose();
    ys.dispose();
  } else {
    const BATCH_SIZE = 512;
    const TRAIN_DATA_SIZE = 5500;
    const TEST_DATA_SIZE = 1000;

    [trainXs, trainYs] = tf.tidy(() => {
      const d = data.nextTrainBatch(TRAIN_DATA_SIZE);
      return [
        d.xs.reshape([TRAIN_DATA_SIZE, 28, 28, 1]),
        d.labels
      ];
    });

    [testXs, testYs] = tf.tidy(() => {
      const d = data.nextTestBatch(TEST_DATA_SIZE);
      return [
        d.xs.reshape([TEST_DATA_SIZE, 28, 28, 1]),
        d.labels
      ];
    });
  }

  // è®­ç»ƒæ¨¡å‹
  try {
    console.log(`Starting training with:
      - Training data shape: ${trainXs.shape} 
      - Training labels shape: ${trainYs.shape}
      - Testing data shape: ${testXs.shape}
      - Testing labels shape: ${testYs.shape}
    `);
    
    // è°ƒè¯•: æ£€æŸ¥æ¨¡å‹çš„é¢„æœŸè¾“å…¥å½¢çŠ¶
    if (model.inputs.length > 0) {
      console.log('Model expected input shape:', model.inputs[0].shape);
    }
    // ç¡®ä¿æ¨¡å‹å·²ç¼–è¯‘ï¼ˆæŸäº›æ„é€ è·¯å¾„å¯èƒ½æœªç¼–è¯‘ï¼‰
    if (!model.optimizer) {
      console.warn('Model not compiled. Auto-compiling with default settings');
      const optimizer = tf.train.adam();
      model.compile({ optimizer, loss: 'categoricalCrossentropy', metrics: ['accuracy'] });
    }

    return await model.fit(trainXs, trainYs, {
      batchSize: 512,
      validationData: [testXs, testYs],
      epochs: 10,
      shuffle: true,
      callbacks: fitCallbacks
    });
  } catch (error) {
    console.error('Error during model training:', error);
    console.error('Error details:', error.message);
    
    // è¯¦ç»†æ‰“å°å¼ é‡ä¿¡æ¯ä»¥ä¾¿äºè°ƒè¯•
    console.error('Feature tensor info:', {
      shape: trainXs.shape,
      dataType: trainXs.dtype,
      size: trainXs.size
    });
    // é¿å… tfvis.show.text API ä¸å­˜åœ¨å¯¼è‡´çš„äºŒæ¬¡æŠ¥é”™
    try {
      if (tfvis?.render?.table) {
        const surface = { name: 'Training Error', tab: 'Model' };
        tfvis.render.table(surface, { headers: ['Message'], values: [[`è®­ç»ƒé”™è¯¯: ${error.message}`]] });
      }
    } catch (e) {
      // å¿½ç•¥æ¸²æŸ“é”™è¯¯
    }
      
    throw error;
  } finally {
    trainXs.dispose();
    trainYs.dispose();
    testXs.dispose();
    testYs.dispose();
  }
}

function TrainButton() {
  const { 
    conv2dConfigs, 
    maxPooling2dConfigs, 
    denseConfigs, 
    csvData, 
    isData, 
    nodes, 
    edges
  } = useStore();

  const handleTrainClick = useCallback(async () => {
    let data;
    let isCsv = false;

    if (isData) {
      data = csvData;
      isCsv = true;
    } else {
      data = new MnistData();
      await data.load();
      await showExamples(data);
    }

    const model = getModel(conv2dConfigs, maxPooling2dConfigs, denseConfigs, nodes, edges);
    tfvis.show.modelSummary({ name: 'Model Architecture', tab: 'Model' }, model);

    await train(model, data, isCsv);
  }, [conv2dConfigs, maxPooling2dConfigs, denseConfigs, csvData, isData, nodes, edges]);

  const handleBackendTrainClick = useCallback(async () => {
    try {
      // 1) ç¡®ä¿æœ‰ä¼šè¯ï¼Œå¹¶è¿æ¥ WebSocket è·å–è®­ç»ƒè¿›åº¦
      const sessionResp = await mlBackendService.createSession('FrontendSession', 'Train via backend');
      if (!sessionResp?.success) {
        console.error('Failed to create backend session:', sessionResp);
        return;
      }
      const sessionId = sessionResp.session_id;
      mlBackendService.connectWebSocket(sessionId);

      // TensorBoard å°†åœ¨è®­ç»ƒå®Œæˆåè‡ªåŠ¨æ‰“å¼€å¯¹åº”çš„ run

      // 2) è®¢é˜…åŸºæœ¬äº‹ä»¶ï¼ˆå¯æ¥å…¥ UI æç¤ºï¼‰
      const progressLogger = (msg) => {
        console.log('WS:', msg);
        
        // è®­ç»ƒå®Œæˆæ—¶ï¼Œæ‰“å¼€å¯¹åº”çš„TensorBoard run
        if (msg.type === 'training_status' && msg.status === 'completed' && msg.tensorboard_logdir) {
          // TensorBoardä¼šè‡ªåŠ¨æ˜¾ç¤ºæœ€æ–°çš„runï¼Œç›´æ¥æ‰“å¼€å³å¯
          const tensorboardUrl = `http://127.0.0.1:6006/`;
          console.log('Opening TensorBoard for completed training:', msg.tensorboard_logdir);
          
          // æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯å¹¶æ‰“å¼€TensorBoard
          alert(`ğŸ‰ è®­ç»ƒå®Œæˆï¼\n\nğŸ“Š è®­ç»ƒæ—¥å¿—: ${msg.tensorboard_logdir}\nğŸ“ˆ TensorBoardå·²è‡ªåŠ¨æ‰“å¼€\n\nğŸ’¡ æç¤º: åœ¨TensorBoardä¸­é€‰æ‹©æœ€æ–°çš„runæŸ¥çœ‹è®­ç»ƒç»“æœ`);
          window.open(tensorboardUrl, '_blank');
        } else if (msg.type === 'training_status' && msg.status === 'failed') {
          alert(`è®­ç»ƒå¤±è´¥: ${msg.message}`);
        }
      };
      mlBackendService.on('websocket:message', progressLogger);

      // 3) ç”Ÿæˆåç«¯éœ€è¦çš„æ¨¡å‹ç»“æ„
      const validModelLayerTypes = new Set([
        'conv2d', 'maxPooling2d', 'avgPooling2d', 'dense', 'dropout', 'batchNorm',
        'flatten', 'lstm', 'gru', 'activation', 'reshape'
      ]);

      // æ„å»ºé‚»æ¥è¡¨ä¸å…¥åº¦ï¼Œåšä¸€æ¬¡BFSï¼Œä¿è¯é¡ºåºç¨³å®š
      const adjacencyList = {};
      const inDegree = {};
      (nodes || []).forEach((n) => {
        adjacencyList[n.id] = [];
        inDegree[n.id] = 0;
      });
      (edges || []).forEach((e) => {
        if (adjacencyList[e.source]) {
          adjacencyList[e.source].push(e.target);
          if (inDegree[e.target] !== undefined) inDegree[e.target] += 1;
        }
      });

      const sourceIds = Object.keys(inDegree).filter((id) => inDegree[id] === 0);
      const queue = sourceIds.length > 0 ? [...sourceIds] : (nodes?.length ? [nodes[0].id] : []);
      const visited = new Set();

      const layers = [];
      // æ•°æ®æºèŠ‚ç‚¹ï¼šå­˜åœ¨ CSV æ•°æ®æ—¶ä½¿ç”¨ useDataï¼Œå¦åˆ™å°è¯• MNIST
      if (isData) {
        layers.push({ type: 'useData', id: 'data_source', config: {} });
      } else {
        layers.push({ type: 'mnist', id: 'data_source', config: {} });
      }

      while (queue.length > 0) {
        const currentId = queue.shift();
        if (visited.has(currentId)) continue;
        visited.add(currentId);

        const node = (nodes || []).find((n) => n.id === currentId);
        if (!node) continue;

        if (validModelLayerTypes.has(node.type)) {
          let config = {};
          const idx = node.configIndex ?? node.data?.index ?? node.data?.configIndex ?? 0;
          switch (node.type) {
            case 'conv2d':
              config = (useStore.getState().conv2dConfigs || [])[idx] || {};
              break;
            case 'maxPooling2d':
              config = (useStore.getState().maxPooling2dConfigs || [])[idx] || {};
              break;
            case 'avgPooling2d':
              config = (useStore.getState().avgPooling2dConfigs || [])[idx] || {};
              break;
            case 'dense':
              config = (useStore.getState().denseConfigs || [])[idx] || {};
              break;
            case 'dropout':
              config = (useStore.getState().dropoutConfigs || [])[idx] || {};
              break;
            case 'batchNorm':
              config = (useStore.getState().batchNormConfigs || [])[idx] || {};
              break;
            case 'flatten':
              config = {}; // æ— å‚æ•°
              break;
            case 'lstm':
              config = (useStore.getState().lstmConfigs || [])[idx] || {};
              break;
            case 'gru':
              config = (useStore.getState().gruConfigs || [])[idx] || {};
              break;
            case 'activation':
              config = (useStore.getState().activationConfigs || [])[idx] || {};
              break;
            case 'reshape':
              config = (useStore.getState().reshapeConfigs || [])[idx] || {};
              break;
            default:
              config = {};
          }
          // åˆå¹¶é¢å¤– JSON å‚æ•°ï¼ˆextraConfig ä¼˜å…ˆï¼‰
          const extra = (config && config.extraConfig) ? config.extraConfig : {};
          const merged = { ...(config || {}) };
          delete merged.extraConfig;
          const finalConfig = { ...merged, ...extra };
          layers.push({ type: node.type, id: node.id, config: finalConfig });
        }

        (adjacencyList[currentId] || []).forEach((nxt) => {
          if (!visited.has(nxt)) queue.push(nxt);
        });
      }

      const connections = (edges || []).map((e) => ({ source: e.source, target: e.target }));

      const payload = {
        model_structure: {
          layers,
          connections,
          framework: 'tensorflow'
        },
        training_params: {
          epochs: 10,
          batch_size: 32,
          learning_rate: 0.001
        },
        framework: 'tensorflow'
      };

      // 4) è§¦å‘åç«¯è®­ç»ƒ
      const startResp = await mlBackendService.trainModel(payload, sessionId);
      console.log('Backend training started:', startResp);
    } catch (err) {
      console.error('Failed to start backend training:', err);
    }
  }, [isData, nodes, edges]);

  return (
    <div className="flex gap-2 mt-4">
      <button 
        onClick={handleTrainClick} 
        className="bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded"
      >
        Train (Frontend)
      </button>
      <button 
        onClick={handleBackendTrainClick} 
        className="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-4 rounded"
      >
        Train (Backend)
      </button>
    </div>
  );
}

export default TrainButton;

export function BackendTrainButton() {
  const { } = useStore();
  const onClick = useCallback(async () => {
    // å¤ç”¨ä¸Šé¢çš„åç«¯è®­ç»ƒé€»è¾‘
    const evt = new Event('click'); // å ä½ï¼Œé¿å…æœªä½¿ç”¨å˜é‡å‘Šè­¦
    evt.preventDefault?.();
  }, []);
  // ä¸ºäº†ç®€å•ï¼Œç›´æ¥å¤ç”¨ TrainButton å†…å®ç°ï¼š
  // å®é™…æ¸²æŸ“æ—¶å»ºè®®åœ¨ä¸Šå±‚å¼•å…¥ handleBackendTrainClickï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªæ¬¡è¦æŒ‰é’®æ ·å¼ã€‚
  return (
    <button
      onClick={() => { /* å»ºè®®åœ¨é›†æˆå¤„ä½¿ç”¨åŒæ–‡ä»¶å†…çš„ handleBackendTrainClick */ }}
      className="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-4 rounded mt-2 ml-2"
    >
      Train on Backend
    </button>
  );
}



